{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff439a24",
   "metadata": {},
   "source": [
    "## TP3 - Bagging, Random Forest and Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6913f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define functions\n",
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(mean_squared_error(y, y_hat))\n",
    "\n",
    "def mape(y, y_hat, eps=1e-5):\n",
    "    return 100 * np.mean(np.abs((y_hat - y) / (np.abs(y) + eps)))\n",
    "\n",
    "def exp_smooth(vec, alpha):\n",
    "    if alpha > 1 or alpha < 0:\n",
    "        return 'alpha doit etre compris entre 0 et 1'\n",
    "    else:\n",
    "        smth = np.full(len(vec), np.nan)\n",
    "        if len(vec) > 0:\n",
    "            smth[0] = vec[0]\n",
    "            if len(vec) > 1:\n",
    "                for i in range(1, len(vec)):\n",
    "                    smth[i] = alpha * smth[i - 1] + (1 - alpha) * vec[i]\n",
    "        return smth\n",
    "\n",
    "# Load data\n",
    "path = '~/Documents/cours/data/'\n",
    "data = pd.read_csv(path + \"data.csv\")\n",
    "data.drop(columns = data.columns[0], axis = 1, inplace= True)\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "\n",
    "data['Vacances'] = data['VacancesZoneA']*1 + data['VacancesZoneB']*1 + data['VacancesZoneC']*1\n",
    "data['JourFerie'] = data['JourFerie']*1\n",
    "data = data.drop(['VacancesZoneA', 'VacancesZoneB', 'VacancesZoneC'], axis=1)\n",
    "\n",
    "# Exponential smoothing for Temperature and Humidity\n",
    "alphas = [0.99, 0.999]\n",
    "for a in alphas:\n",
    "    data['TemperatureSmooth' + str(a)] = exp_smooth(data['Temperature'], alpha=a)\n",
    "    data['HumiditySmooth' + str(a)] = exp_smooth(data['Humidity'], alpha=a)\n",
    "\n",
    "data = pd.get_dummies(data, columns=['Jour', 'JourFerieType', 'Mois'], prefix='', prefix_sep='')\n",
    "data = data.fillna(0)    \n",
    "    \n",
    "#Train-test split\n",
    "n = int(0.5 * len(data))\n",
    "data_train = data.iloc[:n]\n",
    "data_test = data.iloc[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ea268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Regression Tree\n",
    "cart = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: 100 Regression Trees on Bootstrap Samples\n",
    "K = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Model 3: Random Forest with 100 trees\n",
    "rf =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: 100 Random Forests each with 100 trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60032ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of Random Forest: Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeles 5, 6 et 7 : Forêt aléatoire à 100 arbres en ligne \n",
    "# Modele 5 : regression linéaire sur les 100 arbres \n",
    "# Modele 6 : regression linéaire avec poids sur les 100 arbres \n",
    "# Modele 7 : regression linéaire avec pénalisation Ridge sur les 100 arbres \n",
    "\n",
    "data_online_train = pd.DataFrame( data_train[['DateTime','Consommation']])\n",
    "data_online_test = pd.DataFrame(data_test[['DateTime','Consommation']])\n",
    "for tree in range(K):\n",
    "    data_online_train['tree' + str(tree)] = rf.estimators_[tree].predict(data_train.drop(['Consommation', 'DateTime'], axis=1))\n",
    "    data_online_test['tree' + str(tree)] = rf.estimators_[tree].predict(data_test.drop(['Consommation', 'DateTime'], axis=1))\n",
    "\n",
    "\n",
    "for t in range(1, (round(len(data_test) / batch_size) + 2)):\n",
    "    if t == 1:\n",
    "        data_online = data_online_train.copy()\n",
    "    else:\n",
    "        data_online = pd.concat([\n",
    "            data_online,\n",
    "            data_online_test[((t - 2) * batch_size):min(((t - 1) * batch_size), len(data_test))]])\n",
    "\n",
    "    reg_lin = LinearRegression()\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Model 9: XGBoost\n",
    "xgb = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c50534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models 10 and 11: Online XGBoost with CART on Residuals\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
